Predicting Apartment price based on apartment size


import warnings

import matplotlib.pyplot as plt
import pandas as pd
from IPython.display import VimeoVideo
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.utils.validation import check_is_fitted


In this project, you're working for a client who wants to create a model that can predict the price of apartments in the 
city of Buenos Aires — with a focus on apartments that cost less than $400,000 USD.


--------------------------------------------------------------------
### Task
Write a function to clean your data so that it only contains properties in Capital Federal which are apartments and for which
the cost in dollars is less than $400,000


### Solution

def wrangle(filepath):
    df = pd.read_csv(filepath)
    
    # Subset to properties in "Capital Federal"
    mask_ba = df["place_with_parent_names"].str.contains("Capital Federal")
    
    #Subset to Properties that are apartments
    mask_apt = df["property_type"] == "apartment"
    
    # Subset to Properties where price in Dollars is less than 400,000
    mask_price = df["price_aprox_usd"] < 400_000
    
    df = df[mask_ba & mask_apt & mask_price]

    return df

df = wrangle("data/buenos-aires-real-estate-1.csv")
df.head()

# Check your work
assert (
    len(df) <= 1781
), f"`df` should have no more than 1781 observations, not {len(df)}."

-------------------------------------------------------------------------


Task:
Create a histogram of "surface_covered_in_m2". Make sure that the x-axis has the label "Area [sq meters]" and the plot 
has the title "Distribution of Apartment Sizes".

Solution
plt.hist(df["surface_covered_in_m2"])
plt.xlabel("Area [sq meters]")
plt.title("Distribution of Apartment sizes")

-------------------------------------------------------------------------

Task: 
Add to your wrangle function so that it removes observations that are outliers in the "surface_covered_in_m2" column. 
Specifically, all observations should fall between the 0.1 and 0.9 quantiles for "surface_covered_in_m2"

Solution -  add this bit to the wrangle function already created earlier (see above)
low, high = df["surface_covered_in_m2"].quantile([0.1, 0.9])
mask_area = df["surface_covered_in_m2"].between(low, high)
df = df[mask_area]



-------------------------------------------------------------------------

Task:
Create the feature matrix named X_train, which you'll use to train your model. 
It should contain one feature only: ["surface_covered_in_m2"]. Remember that your feature matrix should always be two-dimensional.

Solution
Here we create a variable feature, it contains the dataframe field (independent variable, X house size) we are using to evaluate the dependent variable (house price)
features = ["surface_covered_in_m2"]
X_train = df[features]
X_train.shape

-------------------------------------------------------------------------

Task:
Create the target vector named y_train, which you'll use to train your model. Your target should be "price_aprox_usd". 
Remember that, in most cases, your target vector should be one-dimensional.
My notes: This is the dependent variable (y variable whichh is being predicted)

target = "price_aprox_usd"
y_train = df[target]
y_train.shape

-------------------------------------------------------------------------

Baseline Model

The first step in building a model is baselining. To do this, ask yourself how you will know if the model you build is performing well?" 
One way to think about this is to see how a "dumb" model would perform on the same data. 
Some people also call this a naïve or baseline model, but it's always a model makes only one prediction — in this case, it predicts the same price regardless of an apartment's size. 
So let's start by figuring out what our baseline model's prediction should be. 

As a baseline, we can estimate that the Y value for all X fields will be the mean value of the Y field

Task:
Calculate the mean of your target vector `y_train` and assign it to the variable `y_mean`.

y_mean = y_train.mean()
y_mean


-------------------------------------------------------------------------
Task: 
Create a list named `y_pred_baseline` that contains the value of `y_mean` repeated so that it's the same length at `y`.

y_pred_baseline = [y_mean] * len(y_train)

-------------------------------------------------------------------------

Task:
Add a line to the plot below that shows the relationship between the observations X_train and our dumb model's predictions y_pred_baseline. 
Be sure that the line color is orange, and that it has the label "Baseline Model".

plt.plot(X_train.values, y_pred_baseline, color="orange", label = "Baseline Model")
plt.scatter(X_train, y_train)
plt.xlabel("Area [sq meters]")
plt.ylabel("Price [USD]")
plt.title("Buenos Aires: Price vs. Area")
plt.legend();


-------------------------------------------------------------------------

Task:
Calculate the baseline mean absolute error for your predictions in y_pred_baseline as compared to the true targets in y.

mae_baseline = mean_absolute_error(y_train, y_pred_baseline)

print("Mean apt price", round(y_mean, 2))
print("Baseline MAE:", round(mae_baseline, 2))



Steps in modelling
- Instantiate model - create model for use

- Train model - training the model using our data
    Here we can fit our model to the training data. Example below
    model.fit(X_train, y_train)

    # Check your work
    check_is_fitted(model)

- Prediction -  Use model for prediction

Instantiating our Linear Regression model 

model = LinearRegression()

-------------------------------------------------------------------------


Task:
Using your model's predict method, create a list of predictions for the observations in your feature matrix X_train. Name this array y_pred_training.

y_pred_training = model.predict(X_train)
y_pred_training[:5]

Remember formula for straight line 
Y = mx + b
    where Y is dependent field being calculated
        m is the coefficient - degree of slope of gradient 
        x is independent field used to calculate the outcome
        b is intercept, which is where the line crosses the Y axis

-------------------------------------------------------------------------

Task:
Calculate your training mean absolute error for your predictions in y_pred_training as compared to the true targets in y_train.

mae_training = mean_absolute_error(y_train, y_pred_training)
print("Training MAE:", round(mae_training, 2))

-------------------------------------------------------------------------

Task:

Extract the intercept from your model, and assign it to the variable intercept.

intercept = round(model.intercept_,2)
print("Model Intercept:", intercept)
assert any([isinstance(intercept, int), isinstance(intercept, float)])


-------------------------------------------------------------------------

Task:
Extract the coefficient associated "surface_covered_in_m2" in your model, and assign it to the variable coefficient.

coefficient = round(model.coef_[0], 2)
print('Model coefficient for "surface_covered_in_m2":', coefficient)
assert any([isinstance(coefficient, int), isinstance(coefficient, float)])

-------------------------------------------------------------------------

Task:

Complete the code below and run the cell to print the equation that your model has determined for predicting apartment price based on size

print(f"apt_price = {intercept} + {coefficient} * surface_covered")
result: apt_price = 11433.31 + 2253.12 * surface_covered


-------------------------------------------------------------------------

Task: Add a line to the plot below that shows the relationship between the observations in X_train and your model's predictions y_pred_training. 
Be sure that the line color is red, and that it has the label "Linear Model"

plt.plot(X_train.values, model.predict(X_train), color = "magenta", label = "Linear model")
plt.scatter(X_train, y_train)
plt.xlabel("surface covered [sq meters]")
plt.ylabel("price [usd]")
plt.legend();