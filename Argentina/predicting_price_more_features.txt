2.

import warnings

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import wqet_grader
from IPython.display import VimeoVideo
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.utils.validation import check_is_fitted

warnings.simplefilter(action="ignore", category=FutureWarning)
wqet_grader.init("Project 2 Assessment")
------------------------------------------------------------------------------------


Task
Add to the wrangle function below so that, in the DataFrame it returns, the "lat-lon" column is replaced by separate "lat" and "lon" columns. 
Don't forget to also drop the "lat-lon" column. Be sure to rerun all the cells above before you continue.

def wrangle(filepath):
    # Read CSV file
    df = pd.read_csv(filepath)

    # Subset data: Apartments in "Capital Federal", less than 400,000
    mask_ba = df["place_with_parent_names"].str.contains("Capital Federal")
    mask_apt = df["property_type"] == "apartment"
    mask_price = df["price_aprox_usd"] < 400_000
    df = df[mask_ba & mask_apt & mask_price]

    # Subset data: Remove outliers for "surface_covered_in_m2"
    low, high = df["surface_covered_in_m2"].quantile([0.1, 0.9])
    mask_area = df["surface_covered_in_m2"].between(low, high)
    df = df[mask_area]

    #Split lat-lon column
    df[["lat", "lon"]] = df["lat-lon"].str.split(",", expand= True).astype(float)
    df.drop(columns = "lat-lon", inplace=True)

    return df

------------------------------------------------------------------------------------


Concatenating two dataframes

Task: Use pd.concat to concatenate frame1 and frame2 into a new DataFrame df. Make sure you set the ignore_index argument to True.

df = pd.concat([frame1, frame2], ignore_index = True)
print(df.info())
df.head()

------------------------------------------------------------------------------------

Task
Complete the code below to create a Mapbox scatter plot that shows the location of the apartments in df.

fig = px.scatter_mapbox(
    df,  # Our DataFrame
    lat= "lat",
    lon= "lon",
    width=600,  # Width of map
    height=600,  # Height of map
    color="price_aprox_usd",
    hover_data=["price_aprox_usd"],  # Display price when hovering mouse over house
)

fig.update_layout(mapbox_style="open-street-map")

fig.show()

------------------------------------------------------------------------------------

Task

Complete the code below to create a 3D scatter plot, with "lon" on the x-axis, "lat" on the y-axis, and "price_aprox_usd" on the z-axis.
* Note from Bugo * This is not a very clear way to visualise as it is 3D
Tips: 3D visualizations are often harder for someone to interpret than 2D visualizations. 
We're using one here because it will help us visualize our model once it's built, but as a rule, 
it's better to stick with 2D when your communicating with an audience.


# Create 3D scatter plot
fig = px.scatter_3d(
    df,
    x= "lon",
    y= "lat",
    z= "price_aprox_usd",
    labels={"lon": "longitude", "lat": "latitude", "price_aprox_usd": "price"},
    width=600,
    height=500,
)

# Refine formatting
fig.update_traces(
    marker={"size": 4, "line": {"width": 2, "color": "DarkSlateGrey"}},
    selector={"mode": "markers"},
)

# Display figure
fig.show()

------------------------------------------------------------------------------------

Task
Let's separate our features (latitude and longitude) from our target (price).

features = ["lon", "lat"]
X_train = df[features]
X_train.shape


------------------------------------------------------------------------------------

Task
Create the target vector named y_train, which you'll use to train your model. 
Your target should be "price_aprox_usd". Remember that, in most cases, your target vector should be one-dimensional.

target = "price_aprox_usd"
y_train = df[target]
y_train.shape


------------------------------------------------------------------------------------
Build model Baseline

Task
Calculate the mean of your target vector y_train and assign it to the variable y_mean.
Create a list named y_pred_baseline that contains the value of y_mean repeated so that it's the same length at y_train

y_mean = y_train.mean()
y_pred_baseline = [y_mean] * len(y_train)
y_pred_baseline[:5]

------------------------------------------------------------------------------------

Task
Calculate the baseline mean absolute error for your predictions in y_pred_baseline as compared to the true targets in y_train.

mae_baseline = mean_absolute_error(y_train, y_pred_baseline)

print("Mean apt price", round(y_mean, 2))
print("Baseline MAE:", round(mae_baseline, 2))

------------------------------------------------------------------------------------


Iterate

Because of the math it uses, a linear regression model can't handle observations where there are missing values.
Models generally perform better when they have more data to train with, so every row is precious.
Instead, we can fill in these missing values using information we get from the whole column â€” a process called imputation. 
There are many different strategies for imputing missing values, and one of the most common is filling in the missing values with the mean of the column.

In addition to predictors like LinearRegression, scikit-learn also has transformers that help us deal with issues like missing values.

Task
Instantiate a SimpleImputer named imputer


"""
We need to find a way to deal with missing values because we cannot make predictions with missing values it will return a ValueError- 
Use the transformer first to transform your data, then use predictor afterwards to view the prediction
In scikit learn, you typically should put your transformer and predictor (Linear Regression) into a single package called a pipeline
"""

imputer = SimpleImputer()

Task
Fit your transformer imputer to the feature matrix X.

"""
We need to train our imputer to use it. What the imputer does is to look at each column and identify the missing rows. 
It then fills it with these with the mean of the entire column
We will pass in just the feature matrix (i.e. X_train), as this is the only field we are training)
"""

imputer.fit(X_train)


Task
Use your imputer to transform the feature matrix X_train. Assign the transformed data to the variable XT_train.

XT_train = imputer.transform(X_train)
pd.DataFrame(XT_train, columns=X_train.columns).info()



Pipeline Creation
Create a pipeline named model that contains a SimpleImputer transformer followed by a LinearRegression predictor.

"""
You can have as many transformers as you like to transform your data (Simple imputer in my case), but you can only have one predictor
The predictor comes after all the transformers - in this case my predictor is Linear Regression
"""

model = make_pipeline(
    SimpleImputer(),
    LinearRegression()
)



Train Model after Building Pipeline
Task 
Fit your model to the data, X_train and y_train

model.fit(X_train, y_train)

Evaluate model performance after training

Task: Using your model's predict method, create a list of predictions for the observations in your feature matrix X_train. Name this list y_pred_training.

y_pred_training = model.predict(X_train)

Task: Calculate the training mean absolute error for your predictions in y_pred_training as compared to the true targets in y_train.

mae_training = mean_absolute_error(y_train, y_pred_training)
print("Training MAE:", round(mae_training, 2))



Communicating result

The below is the equation our model has used to predict price based on two variables: latitude and longitude
price = intercept + (coefficient * variable_1) + (coefficient * variable_2)

Task: Extract the intercept and coefficients for your model.

"""
This is going to be different from how we did it when there was just one variable
Because we use the pipeline (containing the imputer and predictor), 
to get the intercept, we have to go into the pipeline and from there go to the predictor to get the intercept and coefficients
The coefficients resulted in an array with two values corresponding to the two variables for longitude and latitude
"""

intercept = model.named_steps["linearregression"].intercept_.round()
coefficients = model.named_steps["linearregression"].coef_.round()


Plotting the data
Complete the code below to create a 3D scatter plot, with "lon" on the x-axis, "lat" on the y-axis, and "price_aprox_usd" on the z-axis

# Create 3D scatter plot
fig = px.scatter_3d(
    df,
    x= "lon",
    y= "lat",
    z= "price_aprox_usd",
    labels={"lon": "longitude", "lat": "latitude", "price_aprox_usd": "price"},
    width=600,
    height=500,
)

# Create x and y coordinates for model representation
x_plane = np.linspace(df["lon"].min(), df["lon"].max(), 10)
y_plane = np.linspace(df["lat"].min(), df["lat"].max(), 10)
xx, yy = np.meshgrid(x_plane, y_plane)

# Use model to predict z coordinates
z_plane = model.predict(pd.DataFrame({"lon": x_plane, "lat": y_plane}))
zz = np.tile(z_plane, (10, 1))

# Add plane to figure
fig.add_trace(go.Surface(x=xx, y=yy, z=zz))

# Refine formatting
fig.update_traces(
    marker={"size": 4, "line": {"width": 2, "color": "DarkSlateGrey"}},
    selector={"mode": "markers"},
)

# Display figure
fig.show()